{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform crowdsourced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/1k_amazon_reviews_crowdsourced.csv')\n",
    "# cut out test questions\n",
    "df = df.loc[df['_golden'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_ids_fig8 = df['_unit_id'].unique()\n",
    "item_ids_dict = dict(zip(item_ids_fig8, np.arange(len(item_ids_fig8))))\n",
    "\n",
    "data_list = []\n",
    "for id_fig8 in item_ids_fig8:\n",
    "    df_item = df.loc[df['_unit_id'] == id_fig8]\n",
    "    data_item = [item_ids_dict[id_fig8]]\n",
    "    is_book_in, is_book_out, is_negative_in, is_negative_out = 0, 0, 0, 0\n",
    "    for _, row in df_item.iterrows():\n",
    "        if row['is_book_crowd'] != 'not_sure':\n",
    "            if row['is_book_crowd'] == '1':\n",
    "                is_book_in += 1\n",
    "            else:\n",
    "                is_book_out += 1\n",
    "        if row['is_negative_crowd'] != 'not_sure':\n",
    "            if row['is_negative_crowd'] == '1':\n",
    "                is_negative_in += 1\n",
    "            else:\n",
    "                is_negative_out += 1\n",
    "    y = 1 if (row['is_book'] == 1 and row['is_negative'] == 1) else 0\n",
    "    data_item += [is_book_in, is_book_out, is_negative_in, is_negative_out, row['is_book'], row['is_negative'], y, row['text']]\n",
    "    data_list.append(data_item)\n",
    "    \n",
    "df_data = pd.DataFrame(data_list, columns=['item_id', 'is_book_in', 'is_book_out', 'is_negative_in',\n",
    "                                             'is_negative_out', 'is_book', 'is_negative', 'Y', 'text'])\n",
    "\n",
    "# uncomment if need to save the dataframe as csv\n",
    "# df_data.to_csv('data/1k_amazon_reviews_crowdsourced_transformed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming, Lemmatising, finding phrases on the AMAZON reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:486: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/1k_amazon_reviews_crowdsourced_transformed.csv')\n",
    "text_cleaned = []\n",
    "\n",
    "# Replace all numbers with special strings\n",
    "regx = re.compile(r\"\\b[\\d.]+\\b\")\n",
    "porter = PorterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    text = row['text']\n",
    "#     with stemming\n",
    "#     text = [porter.stem(word.strip()) for word in nltk.word_tokenize(text.lower()) if (word not in string.punctuation) and (word not in stopwords.words(\"english\"))]\n",
    "    \n",
    "#     # without stemming\n",
    "#     text = [word.strip() for word in nltk.word_tokenize(text.lower()) if (word not in string.punctuation) and (word not in stopwords.words(\"english\"))]\n",
    "    \n",
    "#     # with lemmatizer\n",
    "    text = [wordnet_lemmatizer.lemmatize(word.strip()) for word in nltk.word_tokenize(text.lower()) if (word not in string.punctuation) and (word not in stopwords.words(\"english\"))]\n",
    "         \n",
    "    text_cleaned.append(text)\n",
    "    \n",
    "# Findining Phrases (ie bi-grams)\n",
    "# train bi-grams\n",
    "bigram = Phrases()\n",
    "bigram.add_vocab(text_cleaned)\n",
    "\n",
    "# create phrases\n",
    "text_cleaned_phrases = []\n",
    "for text_ in text_cleaned:\n",
    "    text_cleaned_phrases.append(bigram[text_])\n",
    "\n",
    "text_cleaned_phrases_joined = [' '.join(text) for text in text_cleaned_phrases]\n",
    "df['text'] = pd.Series(text_cleaned_phrases_joined, index=df.index)\n",
    "\n",
    "# uncomment if need to save the dataframe as csv\n",
    "# df.to_csv('data/1k_amazon_reviews_crowdsourced_lemmatized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
